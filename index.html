<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Screen Capture with AI Integration</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      text-align: center;
      padding: 20px;
      font-size: 18px;
    }
    #main {
      display: flex;
      flex-direction: column;
      align-items: center;
    }
    video, canvas {
      width: 70%;
      max-width: 800px;
      border: 2px solid #ccc;
      margin-top: 20px;
    }
    button, input, textarea {
      padding: 10px;
      margin: 10px;
      font-size: 16px;
    }
    input[type="text"], input[type="password"], textarea {
      width: 80%;
      max-width: 800px;
      padding: 8px;
      margin-bottom: 10px;
    }
    #responseContainer {
      margin-top: 20px;
      text-align: left;
      width: 90%;
      max-width: 900px;
      margin-left: auto;
      margin-right: auto;
      border: 2px solid #ccc;
      padding: 20px;
      background-color: #eef5ff;
      font-family: monospace;
      white-space: pre-wrap;
      font-size: 1.3em;
    }
    #overlay {
      position: fixed;
      bottom: 20px;
      right: 20px;
      max-width: 300px;
      max-height: 200px;
      overflow: auto;
      background-color: #eef5ff;
      border: 1px solid #ccc;
      padding: 10px;
      z-index: 1000;
    }
    #overlayHeader {
      display: flex;
      justify-content: flex-end;
      cursor: move;
    }
    #overlayHeader button {
      margin-left: 5px;
    }
    .hidden {
      display: none;
    }
  </style>
</head>
<body>
  <div id="main">
    <h1>Screen Capture with AI Integration</h1>
    <label for="task">Task for AI guidance:</label>
    <input type="text" id="task" value="Guide the user through NIST CSF compliance using Microsoft Azure." />
    <details>
      <summary>Connection Settings</summary>
      <input
        type="text"
        id="apiEndpoint"
        placeholder="Enter AI Endpoint URL"
        value="https://randy-m1scw9rs-eastus2.openai.azure.com/openai/deployments/o1/chat/completions?api-version=2025-01-01-preview"
      />
      <input
        type="password"
        id="apiKey"
        placeholder="Enter API Key"
        value="d74e1b05a7f74630b0a0f9f74ec81229"
      />
    </details>
    <p>Click the button below to start screen capture:</p>
  <button id="captureScreen">Start Screen Capture</button>
  <button id="stopCapture" class="hidden">Stop Capture</button>
  <p>
    <label for="interval">Screenshot Interval (seconds): </label>
    <input type="number" id="interval" value="5" min="1" style="width: 60px;" />
  </p>
  <p><strong>Preview:</strong></p>
  <video id="screenPreview" autoplay muted></video>
  <canvas id="screenshotCanvas" class="hidden"></canvas>
  <div id="responseContainer" class="hidden"></div>
  <button id="showOverlay" class="hidden">Show Overlay</button>
  <div id="overlay" class="hidden">
    <div id="overlayHeader">
      <button id="overlayToggle" title="Show panel">☰</button>
      <button id="overlayPopOut" title="Pop out">↗</button>
    </div>
    <div id="overlayContent"></div>
  </div>
  </div>

  <script>
    // Elements
    const captureButton = document.getElementById('captureScreen');
    const stopButton = document.getElementById('stopCapture');
    const screenPreview = document.getElementById('screenPreview');
    const screenshotCanvas = document.getElementById('screenshotCanvas');
    const intervalInput = document.getElementById('interval');
    const apiEndpointInput = document.getElementById('apiEndpoint');
    const apiKeyInput = document.getElementById('apiKey');
    const taskInput = document.getElementById('task');
    const responseContainer = document.getElementById('responseContainer');
    const showOverlayButton = document.getElementById('showOverlay');
    const overlay = document.getElementById('overlay');
    const overlayContent = document.getElementById('overlayContent');
    const overlayToggle = document.getElementById('overlayToggle');
    const overlayPopOut = document.getElementById('overlayPopOut');
    const overlayHeader = document.getElementById('overlayHeader');

    // Load conversation history from localStorage for lightweight memory
    let conversationHistory = JSON.parse(localStorage.getItem('conversationHistory') || '[]');

    let screenStream;
    let screenshotInterval;
    let lastScreenshotData = '';

    if (conversationHistory.length > 0) {
      responseContainer.classList.remove('hidden');
      responseContainer.textContent = conversationHistory.join('\n\n');
      showOverlayButton.classList.remove('hidden');
      overlayContent.textContent = conversationHistory[conversationHistory.length - 1];
    }

    // Toggle to overlay view
    showOverlayButton.addEventListener('click', () => {
      responseContainer.classList.add('hidden');
      overlay.classList.remove('hidden');
      showOverlayButton.classList.add('hidden');
    });

    // Toggle back to full panel
    overlayToggle.addEventListener('click', () => {
      overlay.classList.add('hidden');
      responseContainer.classList.remove('hidden');
      showOverlayButton.classList.remove('hidden');
    });

    // Pop out into new window or show notification
    overlayPopOut.addEventListener('click', () => {
      if ('Notification' in window) {
        if (Notification.permission === 'granted') {
          new Notification('AI Response', { body: overlayContent.textContent.slice(0, 100) });
        } else if (Notification.permission !== 'denied') {
          Notification.requestPermission().then(p => {
            if (p === 'granted') {
              new Notification('AI Response', { body: overlayContent.textContent.slice(0, 100) });
            }
          });
        } else {
          window.open('').document.write('<pre>' + overlayContent.textContent + '</pre>');
        }
      } else {
        window.open('').document.write('<pre>' + overlayContent.textContent + '</pre>');
      }
    });

    // Simple draggable overlay
    let drag = false, offsetX = 0, offsetY = 0;
    const startDrag = (e) => {
      drag = true;
      offsetX = e.clientX - overlay.offsetLeft;
      offsetY = e.clientY - overlay.offsetTop;
      document.addEventListener('mousemove', onDrag);
      document.addEventListener('mouseup', endDrag);
    };
    const onDrag = (e) => {
      if (!drag) return;
      overlay.style.left = (e.clientX - offsetX) + 'px';
      overlay.style.top = (e.clientY - offsetY) + 'px';
      overlay.style.right = 'auto';
      overlay.style.bottom = 'auto';
    };
    const endDrag = () => {
      drag = false;
      document.removeEventListener('mousemove', onDrag);
      document.removeEventListener('mouseup', endDrag);
    };
    overlayHeader.addEventListener('mousedown', startDrag);

    // Function to start screen capture
    captureButton.addEventListener('click', async () => {
      try {
        const apiEndpoint = apiEndpointInput.value;
        const apiKey = apiKeyInput.value;

        // Ensure both API endpoint and API key are provided
        if (!apiEndpoint || !apiKey) {
          alert("Please enter both the API Endpoint and API Key.");
          return;
        }

        console.log("Starting screen capture...");
        
        // Request permission for screen capture
        screenStream = await navigator.mediaDevices.getDisplayMedia({ video: true });

        // Set the screen stream as the video source
        screenPreview.srcObject = screenStream;

        // Show the stop button and response container
        captureButton.classList.add('hidden');
        stopButton.classList.remove('hidden');
        responseContainer.classList.remove('hidden');
        responseContainer.textContent = conversationHistory.join('\n\n');
        showOverlayButton.classList.remove('hidden');
        overlayContent.textContent = conversationHistory[conversationHistory.length - 1] || '';

        // Immediately send the first screenshot
        takeScreenshotAndSend(apiEndpoint, apiKey, taskInput.value);

        // Schedule further screenshots at the specified interval
        const interval = parseInt(intervalInput.value, 10) * 1000;
        screenshotInterval = setInterval(() => takeScreenshotAndSend(apiEndpoint, apiKey, taskInput.value), interval);
      } catch (err) {
        console.error('Error accessing screen capture:', err);
        alert('Failed to capture screen: ' + err.message);
      }
    });

    // Function to stop screen capture
    stopButton.addEventListener('click', () => {
      if (screenStream) {
        // Stop the screen capture
        screenStream.getTracks().forEach(track => track.stop());
      }
      clearInterval(screenshotInterval);
      screenPreview.srcObject = null;

      // Reset UI
      captureButton.classList.remove('hidden');
      stopButton.classList.add('hidden');
      overlay.classList.add('hidden');
      showOverlayButton.classList.add('hidden');
      console.log("Screen capture stopped.");
    });

    // Function to take a screenshot and send it to the AI endpoint
    async function takeScreenshotAndSend(apiEndpoint, apiKey, task) {
      try {
        const video = screenPreview;
        const canvas = screenshotCanvas;
        const context = canvas.getContext('2d');

        // Set canvas size to match video dimensions
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;

        // Draw the current video frame onto the canvas
        context.drawImage(video, 0, 0, canvas.width, canvas.height);

        // Convert canvas to Base64 image (remove the data URL prefix)
        const screenshotData = canvas.toDataURL('image/jpeg').split(",")[1];

        // Skip sending if screenshot hasn't changed
        if (screenshotData === lastScreenshotData) {
          console.log('Screenshot unchanged, skipping API call.');
          return;
        }
        lastScreenshotData = screenshotData;

        // Send the Base64 image to the AI endpoint
        const response = await sendBase64ToAI(apiEndpoint, apiKey, screenshotData, task);

        // Display the response as plain text for readability
        const messageText = response.choices?.[0]?.message?.content || JSON.stringify(response, null, 2);
        responseContainer.textContent = messageText;
        overlayContent.textContent = messageText;
        console.log("Response received:", messageText);

        // Update lightweight memory with the latest response
        conversationHistory.push(messageText);
        if (conversationHistory.length > 5) {
          conversationHistory = conversationHistory.slice(-5);
        }
        localStorage.setItem('conversationHistory', JSON.stringify(conversationHistory));
      } catch (err) {
        console.error('Error taking screenshot:', err);
      }
    }

    // Function to send the Base64 image to the AI endpoint
    async function sendBase64ToAI(apiEndpoint, apiKey, base64Image, task) {
      try {
        console.log("Sending request to API...");
        const response = await fetch(apiEndpoint, {
          method: 'POST',
          headers: {
            'api-key': apiKey,
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            model: "o1",  // Replace with your model identifier if needed
            messages: [
              {
                role: "user",
                content: [
                  {
                    type: "text",
                    text: `${task}. Based on the screenshot, provide the next steps for the user. Previous guidance: ${conversationHistory.join(' ')}`
                  },
                  {
                    type: "image_url",
                    image_url: {
                      url: `data:image/jpeg;base64,${base64Image}`
                    }
                  }
                ]
              }
            ]
          }),
        });

        if (!response.ok) {
          const errorText = await response.text();
          throw new Error(`Failed to process image: ${response.status} ${response.statusText}\n${errorText}`);
        }

        const result = await response.json();
        console.log("API response received:", result);
        return result;
      } catch (err) {
        console.error('Error sending Base64 to AI:', err);
        throw err;
      }
    }
  </script>
</body>
</html>
