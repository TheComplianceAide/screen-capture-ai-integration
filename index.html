<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Screen Capture with AI Integration</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      text-align: center;
      padding: 20px;
      font-size: 18px;
    }

    #controls {
      width: 300px;
      margin: 0 auto;
      padding: 15px;
      border: 1px solid #ccc;
      border-radius: 8px;
      background: #f7f9fc;
    }

    video,
    canvas {
      width: 40%;
      max-width: 600px;
      border: 2px solid #ccc;
      margin-top: 20px;
    }

    button,
    input {
      padding: 10px;
      margin: 10px;
      font-size: 16px;
    }

    input[type="text"],
    input[type="password"] {
      width: 90%;
      max-width: 280px;
      padding: 8px;
      margin-bottom: 10px;
    }

    #responseContainer {
      position: fixed;
      bottom: 20px;
      left: 50%;
      transform: translateX(-50%);
      width: 90%;
      max-width: 600px;
      border: 2px solid #ccc;
      padding: 20px;
      background-color: rgba(238, 245, 255, 0.95);
      font-family: monospace;
      white-space: pre-wrap;
      font-size: 1.5em;
      z-index: 1000;
    }

    .hidden {
      display: none;
    }
  </style>
</head>
<body>
  <h1>Screen Capture with AI Integration</h1>
  <div id="controls">
    <p>Enter your AI Endpoint and API Key below:</p>
    <input
      type="text"
      id="apiEndpoint"
      placeholder="Enter AI Endpoint URL"
      value="https://randy-m1scw9rs-eastus2.openai.azure.com/openai/deployments/o1/chat/completions?api-version=2025-01-01-preview"
    />
    <input
      type="password"
      id="apiKey"
      placeholder="Enter API Key"
      value="d74e1b05a7f74630b0a0f9f74ec81229"
    />
    <p>Click the button below to start screen capture:</p>
    <button id="captureScreen">Start</button>
    <button id="stopCapture" class="hidden">Stop</button>
    <p>
      <label for="interval">Interval (seconds): </label>
      <input type="number" id="interval" value="5" min="1" style="width: 60px;" />
    </p>
  </div>
  <p><strong>Preview:</strong></p>
  <video id="screenPreview" autoplay muted></video>
  <canvas id="screenshotCanvas" class="hidden"></canvas>
  <div id="responseContainer" class="hidden"></div>

  <script>
    // Elements
    const captureButton = document.getElementById('captureScreen');
    const stopButton = document.getElementById('stopCapture');
    const screenPreview = document.getElementById('screenPreview');
    const screenshotCanvas = document.getElementById('screenshotCanvas');
    const intervalInput = document.getElementById('interval');
    const apiEndpointInput = document.getElementById('apiEndpoint');
    const apiKeyInput = document.getElementById('apiKey');
    const responseContainer = document.getElementById('responseContainer');

    // Load conversation history with 10 minute lifetime
    let storedHistory = JSON.parse(localStorage.getItem('conversationHistory') || 'null');
    let conversationHistory = [];
    if (storedHistory && Date.now() - storedHistory.timestamp < 10 * 60 * 1000) {
      conversationHistory = storedHistory.messages;
    } else {
      localStorage.removeItem('conversationHistory');
    }

    let screenStream;
    let screenshotInterval;
    let lastScreenshot = '';

    if (conversationHistory.length > 0) {
      responseContainer.classList.remove('hidden');
      responseContainer.textContent = conversationHistory.join('\n\n');
    }

    // Function to start screen capture
    captureButton.addEventListener('click', async () => {
      try {
        const apiEndpoint = apiEndpointInput.value;
        const apiKey = apiKeyInput.value;

        // Ensure both API endpoint and API key are provided
        if (!apiEndpoint || !apiKey) {
          alert("Please enter both the API Endpoint and API Key.");
          return;
        }

        console.log("Starting screen capture...");
        
        // Request permission for screen capture
        screenStream = await navigator.mediaDevices.getDisplayMedia({ video: true });

        // Set the screen stream as the video source
        screenPreview.srcObject = screenStream;

        // Show the stop button and response container
        captureButton.classList.add('hidden');
        stopButton.classList.remove('hidden');
        responseContainer.classList.remove('hidden');
        responseContainer.textContent = conversationHistory.join('\n\n');

        // Immediately send the first screenshot
        takeScreenshotAndSend(apiEndpoint, apiKey);

        // Schedule further screenshots at the specified interval
        const interval = parseInt(intervalInput.value, 10) * 1000;
        screenshotInterval = setInterval(() => takeScreenshotAndSend(apiEndpoint, apiKey), interval);
      } catch (err) {
        console.error('Error accessing screen capture:', err);
        alert('Failed to capture screen: ' + err.message);
      }
    });

    // Function to stop screen capture
    stopButton.addEventListener('click', () => {
      if (screenStream) {
        // Stop the screen capture
        screenStream.getTracks().forEach(track => track.stop());
      }
      clearInterval(screenshotInterval);
      screenPreview.srcObject = null;

      // Reset UI
      captureButton.classList.remove('hidden');
      stopButton.classList.add('hidden');
      console.log("Screen capture stopped.");
    });

    // Function to take a screenshot and send it to the AI endpoint
    async function takeScreenshotAndSend(apiEndpoint, apiKey) {
      try {
        const video = screenPreview;
        const canvas = screenshotCanvas;
        const context = canvas.getContext('2d');

        // Set canvas size to match video dimensions
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;

        // Draw the current video frame onto the canvas
        context.drawImage(video, 0, 0, canvas.width, canvas.height);

        // Convert canvas to Base64 image (remove the data URL prefix)
        const screenshotData = canvas.toDataURL('image/jpeg').split(",")[1];

        if (screenshotData === lastScreenshot) {
          console.log('Screenshot unchanged, skipping send');
          return;
        }
        lastScreenshot = screenshotData;

        // Send the Base64 image to the AI endpoint
        const response = await sendBase64ToAI(apiEndpoint, apiKey, screenshotData);

        // Display the response as plain text for readability
        const messageText = response.choices?.[0]?.message?.content || JSON.stringify(response, null, 2);
        responseContainer.textContent = messageText;
        console.log("Response received:", messageText);

        // Update lightweight memory with the latest response
        conversationHistory.push(messageText);
        if (conversationHistory.length > 10) {
          conversationHistory = conversationHistory.slice(-10);
        }
        localStorage.setItem(
          'conversationHistory',
          JSON.stringify({ timestamp: Date.now(), messages: conversationHistory })
        );
      } catch (err) {
        console.error('Error taking screenshot:', err);
      }
    }

    // Function to send the Base64 image to the AI endpoint
    async function sendBase64ToAI(apiEndpoint, apiKey, base64Image) {
      try {
        console.log("Sending request to API...");
        const response = await fetch(apiEndpoint, {
          method: 'POST',
          headers: {
            'api-key': apiKey,
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            model: "o1",  // Replace with your model identifier if needed
            messages: [
              {
                role: "user",
                content: [
                  {
                    type: "text",
                    text: `You are a support assistant guiding the user through a NIST CSF assessment in Microsoft Azure. Provide only the next single step based on the screenshot. If the screenshot has not changed, do not repeat your previous step. Conversation history: ${conversationHistory.join(' ')}`
                  },
                  {
                    type: "image_url",
                    image_url: {
                      url: `data:image/jpeg;base64,${base64Image}`
                    }
                  }
                ]
              }
            ]
          }),
        });

        if (!response.ok) {
          const errorText = await response.text();
          throw new Error(`Failed to process image: ${response.status} ${response.statusText}\n${errorText}`);
        }

        const result = await response.json();
        console.log("API response received:", result);
        return result;
      } catch (err) {
        console.error('Error sending Base64 to AI:', err);
        throw err;
      }
    }
  </script>
</body>
</html>
